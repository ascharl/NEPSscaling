% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/plausible_values.R
\name{plausible_values}
\alias{plausible_values}
\title{Function for estimating plausible values with NEPS competence data and NEPS
scaled item parameters}
\usage{
plausible_values(SC, domain = c("MA", "RE", "SC", "IC", "LI", "EF", "NR",
  "NT", "ORA", "ORB", "ST", "BA", "CD", "GR", "VO"), wave, path,
  bgdata = NULL, npv = 10L, longitudinal = FALSE, rotation = TRUE,
  min_valid = 3L, include_nr = TRUE, verbose = TRUE,
  control = list(EAP = FALSE, WLE = FALSE, ML = list(nmi = 10L, ntheta =
  2000, normal.approx = FALSE, samp.regr = FALSE, theta.model = FALSE,
  np.adj = 8, na.grid = 5, itermcmc = 100, burnin = 50, thin = 1, cartctrl1
  = 5, cartctrl2 = 1e-04)))
}
\arguments{
\item{SC}{numeric. The starting cohort used for the analysis is
indicated by an integer value (e.g., starting cohort one = 1).}

\item{domain}{character. The competence domain of interest is indicated
by the domain abbreviation as used in the variable names (see Fu√ü, D.,
Gnambs, T., Lockl, K., & Attig, M., 2019).}

\item{wave}{numeric. The wave of competence testing is indicated by
an integer value (e.g., wave one = 1).}

\item{path}{character; file path leading to the location of the
competence data}

\item{bgdata}{data frame containing background variables. Categorical
variables have to be specified as factors. If \code{bgdata = NULL}, plausible
values are estimated without a background model. Missing data in the
covariates is imputed using sequential classification and regression trees.}

\item{npv}{numeric; number of plausible values to be estimated;
defaults to 10.}

\item{longitudinal}{logical. TRUE indicating that a unidimensional model
per measurement points is to be estimated and subsequently linked to form
longitudinal estimates. Defaults to FALSE.}

\item{rotation}{logical. TRUE indicating that the competence scores
should be corrected for the rotation design of the booklets. Defaults to
TRUE. If both longitudinal and rotation are TRUE, test rotation is ignored
and the argument rotation is set to FALSE.
automatically.}

\item{min_valid}{numeric; minimum number of valid responses for a test
takers to be included in the estimation process. Defaults to 3 following NEPS
scaling standards (see Pohl & Carstensen, 2012).}

\item{include_nr}{logical; whether the number of not-reached items as a proxy
for processing speed should be included in the background model (the default
is TRUE)}

\item{verbose}{logical; whether progress should be displayed in the console
(the default is TRUE)}

\item{control}{list of additional options. If \code{EAP = TRUE}, the
EAPs will be returned as well; for \code{WLE = TRUE} WLEs are returned.
Furthermore, additional control options for are collected in the list `ML`.
`nmi` denotes the number of multiple impuations for missing covariate data
(defaults to 10); `itermcmc` and `burnin` denote the number of iterations and
and how many are later disregarded as a burnin period of the CART algorithm.
`thin` allows the thinning of CART. `cartctrl1` defines the minimum number of
observations in any terminal CART node (defaults to 5), `cartctrl2` determines the minimum
decrease of overall lack of fit by each CART split (defaults to 0.0001).}
}
\value{
\code{plausible_values()} returns an object of class \code{pv_obj}
containing:
\describe{
\item{SC}{Starting cohort that plausible values were estimated for}
\item{domain}{Competence domain that plausible values were estimated for}
\item{wave}{Wave that plausible values were estimated for}
\item{type}{Whether cross-sectional ("cross") or longitudinal ("long")
plausible values were estimated}
\item{rotation}{In most assessments the position of the competence test was
rotated with another competence domain. If this was the case for the
specific estimation, this variable indicates whether the correction was
applied. Depending on the estimation context, this variable may have been
automatically set by the function and thus differ from user input}
\item{min_valid}{The minimum number of answers a test taker must have given}
\item{valid_responses_per_person}{A \code{data.frame} containing the \code{ID_t} and the
number of valid responses given by the respective individual}
\item{npv}{The number of plausible values that are returned by the function}
\item{control}{The control variables that were applied to fine-tune the
estimation algorithms}
\item{position}{A \code{data.frame} containing the \code{ID_t} and the
position the respective individual got the testlet in (first or second)}
\item{mean.PV}{The overall mean of all persons' abilities}
\item{pv}{A list of \code{data.frame}s containing one plausible value each
and the imputed data set that was used to estimate the plausible value.
Additionally, if \code{include_nr} was specified, the background model is
enriched by the number of not reached items (\code{nr}) per test taker as a
proxy for response times.}
\item{items}{The fixed item difficulty and the SE per item are returned as
a `data.frame`}
\item{eap}{A \code{data.frame} containing the \code{ID_t} and the ability
EAP value for the respective individual}
\item{wle}{A \code{data.frame} containing the \code{ID_t} and the ability
WLE value for the respective individual}
\item{regr.coeff}{The regression coefficients of the latent regression of
the ability}
\item{EAP.rel}{The EAP reliability is returned}
}
}
\description{
Function for estimating plausible values with NEPS competence data and NEPS
scaled item parameters
}
\note{
For an extensive example, see the accompanying NEPS Survey Paper.
The function will only work with NEPS data. To access NEPS data see
https://www.neps-data.de/en-us/datacenter/dataaccess.aspx.
}
\examples{
\dontrun{
rm(list = ls())
library(NEPScaling)
library(foreign)
## read in data object for conditioning variables
data(bg_data)
bg_data$gender <- as.factor(bg_data$gender)
## define path to NEPS competence data
path <- "Usr/NEPS-data/"
setwd(path)
## save simulated target competencies to path
data(xTargetCompetencies_sim)
write.dta(
  dataframe = xTargetCompetencies_sim,
  file = "SC6_xTargetCompetencies_sim.dta"
)
## estimate default number of 10 plausible values
## note: the example background data is completely observed!
result <- plausible_values(
  SC = 6,
  domain = "RE",
  wave = 3,
  bgdata = bg_data,
  path = path
)
}

}
\references{
Albert, J. H. (1992). Bayesian estimation of normal ogive item
response curves using Gibbs sampling. \emph{Journal of Educational
Statistics}, \emph{17}(3), 251-269.

Azur, M. J., Stuart, E. A., Frangakis, C., & Leaf, P. J. (2011).
Multiple imputation by chained equations: what is it and how does it work?
\emph{International Journal of Methods in Psychiatric Research, 20}(1), 40-49.

Blossfeld, H.-P., Rossbach, H.-G., & von Maurice,  J. (Eds.)
(2011). Education as a Lifelong Process - The German National Educational
Panel Study (NEPS). \emph{Zeitschrift fuer Erziehungswissenschaft,
Sonderheft 14}.

Burgette, L. F., & Reiter, J. P. (2010). Multiple imputation for
missing data via sequential regression trees. \emph{American Journal of
Epidemiology}, \emph{172}(9), 1070-1076.

Mislevy, R. J. (1991). Randomization-based inference about latent
variables from complex samples. \emph{Psychometrika, 56}(2), 177-196.

Pohl, S., & Carstensen, C. H. (2012). NEPS technical report -
Scaling the data of the competence tests.

Scharl, A., Carstensen, C. H., & Gnambs, T. (2019).
\emph{Estimating Plausible Values with NEPS Data: An Example Using Reading
Competence in Starting Cohort 6 (NEPS Survey Paper No. XX)}. Bamberg: Leibniz
Institute for Educational Trajectories, National Educational Panel Study.

Tanner, M. A., & Wong, W. H. (1987). The calculation of posterior
distributions by data augmentation. \emph{Journal of the American Statistical
Association}, \emph{82}(398), 528-549.

Weirich, S., Haag, N., Hecht, M., Boehme, K., Siegle, T., &
Luedtke, O. (2014). Nested multiple imputation in large-scale assessments.
\emph{Large-Scale Assessments in Education, 2}(1), 9.
}
